{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import ndcg_score\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions df shape:                       (100, 6)\n"
     ]
    }
   ],
   "source": [
    "size = 'demo'\n",
    "type_ = 'validation'\n",
    "predictions_df_path = f'./files/pickle/predictions_df_{size}_{type_}.pkl'\n",
    "predictions_df = pd.read_pickle(predictions_df_path)\n",
    "print('Predictions df shape:                      ',predictions_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_ids_inview</th>\n",
       "      <th>article_ids_clicked</th>\n",
       "      <th>Predicted_read_times</th>\n",
       "      <th>Predicted_tuples_sorted</th>\n",
       "      <th>Predicted_article_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76658</td>\n",
       "      <td>[9788239, 9780702, 9553264, 9787499, 6741781, ...</td>\n",
       "      <td>[9783042]</td>\n",
       "      <td>[159.59189, 118.70199, 17.448689, 41.142696, 1...</td>\n",
       "      <td>[(9788239, 159.59189), (9780702, 118.70199), (...</td>\n",
       "      <td>[9788239, 9780702, 9787499, 9553264, 9783042, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76658</td>\n",
       "      <td>[9788521, 9786217, 9553264, 9788361, 9788352, ...</td>\n",
       "      <td>[9788125]</td>\n",
       "      <td>[18.174896, 41.932983, 17.448689, 11.244547, 2...</td>\n",
       "      <td>[(9788125, 222.22842), (9786217, 41.932983), (...</td>\n",
       "      <td>[9788125, 9786217, 9788352, 9788521, 9553264, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                 article_ids_inview  \\\n",
       "0    76658  [9788239, 9780702, 9553264, 9787499, 6741781, ...   \n",
       "1    76658  [9788521, 9786217, 9553264, 9788361, 9788352, ...   \n",
       "\n",
       "  article_ids_clicked                               Predicted_read_times  \\\n",
       "0           [9783042]  [159.59189, 118.70199, 17.448689, 41.142696, 1...   \n",
       "1           [9788125]  [18.174896, 41.932983, 17.448689, 11.244547, 2...   \n",
       "\n",
       "                             Predicted_tuples_sorted  \\\n",
       "0  [(9788239, 159.59189), (9780702, 118.70199), (...   \n",
       "1  [(9788125, 222.22842), (9786217, 41.932983), (...   \n",
       "\n",
       "                               Predicted_article_ids  \n",
       "0  [9788239, 9780702, 9787499, 9553264, 9783042, ...  \n",
       "1  [9788125, 9786217, 9788352, 9788521, 9553264, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reciprocal_rank(row):\n",
    "    predicted_item_list = row['Predicted_article_ids']\n",
    "    clicked_article = row['article_ids_clicked'][0]\n",
    "    try:\n",
    "        index = predicted_item_list.index(clicked_article)\n",
    "        # Return the reciprocal rank\n",
    "        return 1 / (index + 1)\n",
    "    except ValueError:\n",
    "        # If the clicked article is not in the predicted list, return 0\n",
    "        return 0\n",
    "    \n",
    "def calculate_precision(target, predictions):\n",
    "    tp = predictions.count(target)  # Count true positives\n",
    "    fp = len(predictions) - tp  # Calculate false positives\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0  # Compute precision\n",
    "    return precision\n",
    "\n",
    "def calculate_recall(target, predictions):\n",
    "    tp = predictions.count(target)  # True Positives: target in predictions\n",
    "    fn = 1 if tp == 0 else 0  # False Negatives: target not in predictions\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0  # Compute recall\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 33325.15it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 50003.62it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 50057.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_ids_inview</th>\n",
       "      <th>article_ids_clicked</th>\n",
       "      <th>Predicted_read_times</th>\n",
       "      <th>Predicted_tuples_sorted</th>\n",
       "      <th>Predicted_article_ids</th>\n",
       "      <th>MMR_rank</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76658</td>\n",
       "      <td>[9788239, 9780702, 9553264, 9787499, 6741781, ...</td>\n",
       "      <td>[9783042]</td>\n",
       "      <td>[159.59189, 118.70199, 17.448689, 41.142696, 1...</td>\n",
       "      <td>[(9788239, 159.59189), (9780702, 118.70199), (...</td>\n",
       "      <td>[9788239, 9780702, 9787499, 9553264, 9783042, ...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76658</td>\n",
       "      <td>[9788521, 9786217, 9553264, 9788361, 9788352, ...</td>\n",
       "      <td>[9788125]</td>\n",
       "      <td>[18.174896, 41.932983, 17.448689, 11.244547, 2...</td>\n",
       "      <td>[(9788125, 222.22842), (9786217, 41.932983), (...</td>\n",
       "      <td>[9788125, 9786217, 9788352, 9788521, 9553264, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                 article_ids_inview  \\\n",
       "0    76658  [9788239, 9780702, 9553264, 9787499, 6741781, ...   \n",
       "1    76658  [9788521, 9786217, 9553264, 9788361, 9788352, ...   \n",
       "\n",
       "  article_ids_clicked                               Predicted_read_times  \\\n",
       "0           [9783042]  [159.59189, 118.70199, 17.448689, 41.142696, 1...   \n",
       "1           [9788125]  [18.174896, 41.932983, 17.448689, 11.244547, 2...   \n",
       "\n",
       "                             Predicted_tuples_sorted  \\\n",
       "0  [(9788239, 159.59189), (9780702, 118.70199), (...   \n",
       "1  [(9788125, 222.22842), (9786217, 41.932983), (...   \n",
       "\n",
       "                               Predicted_article_ids  MMR_rank  Precision@10  \\\n",
       "0  [9788239, 9780702, 9787499, 9553264, 9783042, ...       0.2      0.166667   \n",
       "1  [9788125, 9786217, 9788352, 9788521, 9553264, ...       1.0      0.142857   \n",
       "\n",
       "   Recall@10  \n",
       "0        1.0  \n",
       "1        1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df['MMR_rank'] = predictions_df.progress_apply(get_reciprocal_rank,axis=1)\n",
    "predictions_df['Precision@10']= predictions_df.progress_apply(lambda row: calculate_precision(row['article_ids_clicked'][0],row['Predicted_article_ids']),axis=1)\n",
    "predictions_df['Recall@10']= predictions_df.progress_apply(lambda row: calculate_recall(row['article_ids_clicked'][0],row['Predicted_article_ids']),axis=1)\n",
    "predictions_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR:  0.36013888888888884\n",
      "Precision@10:  0.1269404761904762\n",
      "Recall@10:  0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"MRR: \", predictions_df['MMR_rank'].sum()/predictions_df.shape[0])\n",
    "print(\"Precision@10: \", predictions_df['Precision@10'].sum()/predictions_df.shape[0])\n",
    "print(\"Recall@10: \", predictions_df['Recall@10'].sum()/predictions_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "- An MRR of approximately 0.299 means that, on average, the true positive item is found at about the third position in the recommendation list (since 1/0.299≈3.34). This is a reasonably good result, indicating that the recommender system often ranks the relevant items near the top of the recommendation list.\n",
    "\n",
    "- A Precision@10 of approximately 0.128 means that about 12.8% of the items in the top 10 recommendations are relevant. This indicates that for every 10 items recommended, around 1.28 items are relevant. This precision value suggests that there is room for improvement in terms of recommending more relevant items in the top 10.\n",
    "\n",
    "- A Recall@10 of 0.86 means that the recommender system successfully identifies 86% of the relevant items within the top 10 recommendations. This high recall value indicates that the system is very effective at finding relevant items, though they may not always be ranked at the very top of the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Interpretation\n",
    "- MRR (0.299): The relevant items are generally ranked around the third position on average.\n",
    "- Precision@10 (0.128): About 12.8% of the top 10 recommendations are relevant, indicating room for improvement in the quality of top recommendations.\n",
    "- Recall@10 (0.86): The system successfully finds 86% of the relevant items within the top 10 recommendations, showing strong recall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve precision and MRR for your recommender system, you can consider various strategies that involve improving your preprocessing, model, and recommendation logic. Here are some approaches:\n",
    "\n",
    "1. Data Preprocessing Improvements\n",
    "    1. Feature Engineering:\n",
    "\n",
    "        - Add More Features: Incorporate additional features that could influence reading time predictions, such as article length, topic, author, publication date, user preferences, etc.\n",
    "        - Normalization and Scaling: Ensure that your features are properly normalized and scaled to help the model learn more effectively.\n",
    "        - Categorical Features: Use techniques like one-hot encoding or embeddings for categorical features (e.g., article categories or authors).\n",
    "\n",
    "    2. Data Cleaning:\n",
    "\n",
    "        - Remove Outliers: Identify and remove or handle outliers in reading times to ensure the model isn’t biased by extreme values.\n",
    "        - Handle Missing Values: Ensure any missing values in the dataset are properly handled through imputation or removal.\n",
    "\n",
    "    3. Data Augmentation:\n",
    "\n",
    "        - Synthetic Data: If your dataset is small, consider generating synthetic data to improve model training.\n",
    "\n",
    "2. Model Improvements\n",
    "\n",
    "    1. Model Architecture:\n",
    "\n",
    "        - Experiment with Different Architectures: Try different neural network architectures such as deeper networks, recurrent neural networks (RNNs), transformers, etc.\n",
    "    - Hyperparameter Tuning: Perform hyperparameter tuning to find the optimal parameters for your model (learning rate, batch size, number of layers, units per layer, etc.).\n",
    "\n",
    "    2. Training Techniques:\n",
    "\n",
    "        - Regularization: Use regularization techniques like dropout, L2 regularization, and early stopping to prevent overfitting.\n",
    "        - Ensemble Methods: Combine predictions from multiple models using ensemble methods (e.g., bagging, boosting) to improve accuracy and robustness.\n",
    "\n",
    "3. Recommendation Logic Improvements\n",
    "\n",
    "    1. Post-Processing Predictions:\n",
    "\n",
    "        - Re-Ranking: After predicting reading times, re-rank articles using additional criteria such as user preferences, recent trends, or article popularity.\n",
    "        - Hybrid Recommendations:\n",
    "\n",
    "        - Combine Models: Use a hybrid approach that combines collaborative filtering, content-based filtering, and your read time prediction model to recommend articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
