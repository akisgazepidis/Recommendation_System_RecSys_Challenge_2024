{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13fdfa59-d51c-4ed3-8adf-1347e081cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RS- Word2Vec new Embedding- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ee1b42e-7d22-4094-9383-ee5ecdafc038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyncone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab1d28d0-8bfd-4121-ace5-d6e30dcf8da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Large- Error with embeddings\n",
    "# ----------------------------\n",
    "# Word2Vec - > Embeddings - Initialized - new article ? -> How to create a vector for this new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db77ed8",
   "metadata": {},
   "source": [
    "## Context based Approach using Tf-idf, Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f258dd42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\giwrg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('da_core_news_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary libraries\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "import subprocess\n",
    "subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"da_core_news_sm\"])\n",
    "\n",
    "nlp = spacy.load('da_core_news_sm')\n",
    "\n",
    "# Download Danish stop words from NLTK\n",
    "nltk.download('stopwords')\n",
    "danish_stop_words = set(stopwords.words('danish'))\n",
    "# Load the Danish spaCy model\n",
    "spacy.cli.download(\"da_core_news_sm\")\n",
    "nlp = spacy.load('da_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b5bb99",
   "metadata": {},
   "source": [
    "## TF-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee219de",
   "metadata": {},
   "source": [
    "#### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c63f07c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "size = 'demo'\n",
    "type_ = 'train'\n",
    "articles_path = f\"./files/parquet/ebnerd_{size}/articles.parquet\"\n",
    "df_articles = pd.read_parquet(articles_path)\n",
    "\n",
    "# Work only with the body column\n",
    "df_articles_body = df_articles[['body']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547042b",
   "metadata": {},
   "source": [
    "#### Preprocess the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f209dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giwrg\\AppData\\Local\\Temp\\ipykernel_10448\\238926766.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_articles_body['processed_content'] = df_articles_body['body'].apply(preprocess_text)\n",
      "C:\\Users\\giwrg\\AppData\\Local\\Temp\\ipykernel_10448\\238926766.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_articles_body.drop(\"body\", axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-ZæøåÆØÅ\\s]', '', text)\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if token.text not in danish_stop_words and not token.is_punct]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "df_articles_body['processed_content'] = df_articles_body['body'].apply(preprocess_text)\n",
    "df_articles_body.drop(\"body\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efa4789",
   "metadata": {},
   "source": [
    "#### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b873d985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Tf-idf model and apply it to the docs\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_articles_body['processed_content'])\n",
    "\n",
    "# Find the cosine similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "cosine_sim_df = pd.DataFrame(cosine_sim, index=df_articles_body.index, columns=df_articles_body.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e53db10",
   "metadata": {},
   "source": [
    "#### Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f58afe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles similar to article 0: [(3430, 0.22637903660754571), (4255, 0.20733735683736004), (9268, 0.18233629146389696), (792, 0.17701128174711836), (2626, 0.1584519494329333)]\n"
     ]
    }
   ],
   "source": [
    "# Example function to get similar articles\n",
    "def get_similar_articles(article_index, cosine_sim_matrix, top_n=5):\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[article_index]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:top_n+1]\n",
    "    similar_articles = [(index, score) for index, score in sim_scores]\n",
    "    return similar_articles\n",
    "\n",
    "# Example usage\n",
    "article_index = 0 \n",
    "similar_articles = get_similar_articles(article_index, cosine_sim)\n",
    "print(f\"Articles similar to article {article_index}: {similar_articles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76abf12f",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eae0d05",
   "metadata": {},
   "source": [
    "#### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7020ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset once again \n",
    "df_articles_body = df_articles[['body']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115bb058",
   "metadata": {},
   "source": [
    "#### Preprocess the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d94a674f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giwrg\\AppData\\Local\\Temp\\ipykernel_10448\\3570535638.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_articles_body['processed_content'] = df_articles_body['body'].apply(preprocess_text_w2v)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text_w2v(text):\n",
    "    text = re.sub(r'[^a-zA-ZæøåÆØÅ\\s]', '', text)\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if token.text not in danish_stop_words and not token.is_punct]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "df_articles_body['processed_content'] = df_articles_body['body'].apply(preprocess_text_w2v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c965f",
   "metadata": {},
   "source": [
    "#### Train Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25cf3bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_articles_body['processed_content'].tolist()\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d91d6",
   "metadata": {},
   "source": [
    "#### Function to compute the average vector for a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88ba35d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(doc, model):\n",
    "    # Remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in model.wv.index_to_key]\n",
    "    if len(doc) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(model.wv[doc], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46350b38",
   "metadata": {},
   "source": [
    "#### Compute document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "432b0342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giwrg\\AppData\\Local\\Temp\\ipykernel_10448\\3058639058.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_articles_body['doc_vector'] = df_articles_body['processed_content'].apply(lambda x: document_vector(x, word2vec_model))\n"
     ]
    }
   ],
   "source": [
    "df_articles_body['doc_vector'] = df_articles_body['processed_content'].apply(lambda x: document_vector(x, word2vec_model))\n",
    "doc_vectors = np.stack(df_articles_body['doc_vector'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016d8483",
   "metadata": {},
   "source": [
    "#### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe64f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(doc_vectors)\n",
    "cosine_sim_df = pd.DataFrame(cosine_sim, index=df_articles_body.index, columns=df_articles_body.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5383083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Articles:\n",
      "[(439, 0.98844374983732), (9304, 0.9878260624412174), (2975, 0.9871099786582396), (9041, 0.9870656407868641), (2427, 0.9868525744860396)]\n"
     ]
    }
   ],
   "source": [
    "def get_similar_articles(article_index, cosine_sim_matrix, df, top_n=5):\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[article_index]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:top_n+1]\n",
    "    similar_articles = [(df.index[i], score) for i, score in sim_scores]\n",
    "    return similar_articles\n",
    "# Example \n",
    "article_index = 0 \n",
    "similar_articles = get_similar_articles(article_index, cosine_sim, df_articles_body)\n",
    "print(\"Similar Articles:\")\n",
    "print(similar_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a72cb7-e380-4412-a11d-d26524064165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
